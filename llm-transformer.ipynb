{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training a Transformer Model on Custom Data\n",
        "\n",
        "This notebook demonstrates how to set up, configure, and train a Transformer model using a custom dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/ibrardu/llm-transformer.git\n",
        "\n",
        "# Navigate to the cloned repository\n",
        "%cd llm-transformer\n",
        "\n",
        "# Install the required dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Create an empty __init__.py file in the models directory\n",
        "!touch models/__init__.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "data_path = 'data/your_dataset.txt'  # Modify this line with your actual dataset path\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Preprocess the dataset\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))  # 90% for training, rest for validation\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "print(f\"Training data size: {len(train_data)}\")\n",
        "print(f\"Validation data size: {len(val_data)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch.nn as nn\n",
        "from models.bigram_model import BigramLanguageModel\n",
        "\n",
        "# Configuration\n",
        "n_layer = 6\n",
        "n_head = 4\n",
        "n_embd = 256\n",
        "block_size = 64\n",
        "dropout = 0.0\n",
        "learning_rate = 1e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Initialize model\n",
        "model = BigramLanguageModel(vocab_size, n_embd, n_head, n_layer, block_size, dropout)\n",
        "model.to(device)\n",
        "\n",
        "# Print the number of parameters\n",
        "print(f\"Model has {sum(p.numel() for p in model.parameters() if p.requires_grad)} trainable parameters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "batch_size = 16\n",
        "eval_interval = 100\n",
        "eval_iters = 200\n",
        "max_iters = 10000\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for iter in range(max_iters):\n",
        "    # Evaluate loss on train and val sets every eval_interval\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "    \n",
        "    # Sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "    \n",
        "    # Evaluate the loss and perform backpropagation\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_text = decode(model.generate(context, max_new_tokens=2000)[0].tolist())\n",
        "print(generated_text)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
